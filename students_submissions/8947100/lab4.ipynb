{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred_linear = linear_reg.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_bmi = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_bmi_poly = poly_reg_bmi.fit_transform(X_train[:, [2]])\n",
    "X_valid_bmi_poly = poly_reg_bmi.transform(X_valid[:, [2]])\n",
    "linear_reg_bmi_poly = LinearRegression()\n",
    "linear_reg_bmi_poly.fit(X_train_bmi_poly, y_train)\n",
    "y_pred_bmi_poly = linear_reg_bmi_poly.predict(X_valid_bmi_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_all = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_all_poly = poly_reg_all.fit_transform(X_train)\n",
    "X_valid_all_poly = poly_reg_all.transform(X_valid)\n",
    "linear_reg_all_poly = LinearRegression()\n",
    "linear_reg_all_poly.fit(X_train_all_poly, y_train)\n",
    "y_pred_all_poly = linear_reg_all_poly.predict(X_valid_all_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate Linear Regression:\n",
      "R-squared: 0.5112619269090262\n",
      "MAPE: 34.61633710712247%\n",
      "MAE: 38.216681372349036\n",
      "\n",
      "Polynomial Regression on BMI:\n",
      "R-squared: 0.296223055272985\n",
      "MAPE: 41.90243458933215%\n",
      "MAE: 48.27302777867063\n",
      "\n",
      "Multivariate Polynomial Regression:\n",
      "R-squared: 0.36717480117280155\n",
      "MAPE: 38.08962481749319%\n",
      "MAE: 42.47137889140918\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    r_squared = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return r_squared, mape, mae\n",
    "\n",
    "r_squared_linear, mape_linear, mae_linear = evaluate_model(y_valid, y_pred_linear)\n",
    "r_squared_bmi_poly, mape_bmi_poly, mae_bmi_poly = evaluate_model(y_valid, y_pred_bmi_poly)\n",
    "r_squared_all_poly, mape_all_poly, mae_all_poly = evaluate_model(y_valid, y_pred_all_poly)\n",
    "\n",
    "print(\"Multivariate Linear Regression:\")\n",
    "print(f\"R-squared: {r_squared_linear}\")\n",
    "print(f\"MAPE: {mape_linear}%\")\n",
    "print(f\"MAE: {mae_linear}\")\n",
    "\n",
    "print(\"\\nPolynomial Regression on BMI:\")\n",
    "print(f\"R-squared: {r_squared_bmi_poly}\")\n",
    "print(f\"MAPE: {mape_bmi_poly}%\")\n",
    "print(f\"MAE: {mae_bmi_poly}\")\n",
    "\n",
    "print(\"\\nMultivariate Polynomial Regression:\")\n",
    "print(f\"R-squared: {r_squared_all_poly}\")\n",
    "print(f\"MAPE: {mape_all_poly}%\")\n",
    "print(f\"MAE: {mae_all_poly}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.03259528  0.08540807 -0.0105172   0.11019775 -0.00620595  0.00133873\n  0.114509   -0.04069594  0.01750591  0.05954058 -0.046085    0.04768465\n  0.00564998 -0.03099563  0.05415152 -0.00512814 -0.00943939  0.0250506\n  0.12852056  0.01427248 -0.00081689 -0.03099563  0.00457217  0.00996123\n -0.03099563 -0.03854032  0.00241654 -0.02560657 -0.06656343 -0.03961813\n -0.04716281 -0.03207344  0.00241654  0.04552903 -0.0547075  -0.03854032\n -0.01590626 -0.01159501 -0.08919748 -0.02560657  0.02289497  0.06169621\n -0.00728377  0.08001901  0.06061839  0.05630715 -0.02560657  0.00457217\n  0.00672779 -0.0277622  -0.04716281 -0.00405033 -0.03961813 -0.06548562\n  0.0703187   0.02720622  0.02397278 -0.08380842  0.07139652  0.04121778\n -0.02237314  0.07139652 -0.05901875  0.06924089  0.00672779  0.0164281\n  0.05415152 -0.04177375  0.04013997  0.06816308 -0.05901875 -0.04824063\n -0.02452876  0.07247433 -0.0816528   0.09295276  0.04445121  0.00457217\n -0.05578531 -0.046085   -0.02991782  0.0347509  -0.01375064  0.00996123\n  0.00564998 -0.04824063 -0.03422907 -0.02560657  0.08864151  0.00672779\n -0.02991782  0.06061839  0.01103904  0.04660684  0.08109682  0.03367309\n  0.00133873  0.00564998 -0.01482845  0.03906215  0.10480869  0.12744274\n  0.06492964 -0.02991782 -0.00728377  0.04768465 -0.00836158  0.05954058\n -0.03315126 -0.06225218 -0.02345095 -0.01267283 -0.07518593 -0.00943939\n -0.04177375  0.0164281   0.08864151  0.00241654  0.05522933 -0.04716281\n -0.03530688 -0.02345095  0.04013997 -0.0105172   0.02181716  0.02073935\n -0.01590626  0.00888341 -0.01375064  0.07678558 -0.04069594  0.00672779\n  0.03690653 -0.02452876 -0.0191397  -0.0816528   0.00349435 -0.02452876\n  0.00026092  0.00133873  0.00457217 -0.06656343 -0.03315126 -0.00836158\n -0.00189471 -0.03854032  0.04984027 -0.02991782 -0.05362969  0.06169621\n  0.06816308 -0.08057499 -0.02452876 -0.05255187  0.07139652 -0.02345095\n  0.04229559  0.0433734  -0.02884001 -0.03099563 -0.02129532 -0.02021751\n  0.01211685 -0.07195249  0.03367309 -0.03854032 -0.05794093  0.0164281\n  0.07462995 -0.05686312  0.08540807 -0.00836158 -0.06764124 -0.03638469\n  0.02612841 -0.00512814  0.05630715 -0.03854032 -0.03638469  0.16085492\n -0.03099563  0.01750591 -0.046085    0.00996123 -0.07087468 -0.046085\n -0.00512814 -0.02237314  0.09403057  0.00457217 -0.0730303   0.12528712\n -0.00081689 -0.05794093  0.01858372  0.05954058 -0.02884001  0.07139652\n -0.00836158 -0.01698407  0.03043966 -0.00297252  0.11127556 -0.00728377\n  0.05630715 -0.06225218  0.06169621 -0.00836158 -0.02560657  0.07355214\n -0.02560657 -0.0105172  -0.00836158  0.12313149  0.04984027  0.03582872\n -0.02452876  0.06061839 -0.01267283  0.00672779  0.04552903  0.00349435\n  0.03906215  0.097264    0.09834182 -0.03099563  0.05415152  0.0347509\n  0.06061839 -0.03207344 -0.05578531  0.06385183 -0.02345095  0.03151747\n -0.01267283  0.00133873 -0.03638469 -0.03207344 -0.01590626 -0.05147406\n -0.03422907  0.01427248  0.01211685  0.04660684 -0.06332999 -0.07734155\n  0.13714305  0.0519959  -0.00728377 -0.00943939 -0.00297252  0.02828403\n -0.00836158 -0.00189471 -0.02021751 -0.04069594  0.01535029 -0.02021751\n -0.06009656  0.06708527  0.00133873  0.0433734  -0.00189471  0.01103904\n  0.00457217 -0.046085    0.0250506  -0.02452876 -0.00728377  0.00996123\n -0.06656343 -0.01590626 -0.0547075  -0.02668438 -0.06440781 -0.04177375\n -0.01159501 -0.01482845  0.05954058 -0.02237314  0.05307371 -0.06225218\n  0.02612841 -0.04177375 -0.0191397   0.09295276 -0.00081689  0.01858372\n -0.05578531 -0.046085   -0.00512814  0.09618619 -0.00405033  0.00564998\n -0.06440781 -0.02345095 -0.00620595  0.03043966 -0.03315126  0.01750591\n -0.0730303  -0.05686312 -0.00297252  0.03367309 -0.07626374  0.03043966\n -0.02021751 -0.02345095  0.02828403].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\akash\\Documents\\my_python_code\\ran\\CSCN8010-lab-submissions\\students_submissions\\8947100\\lab4.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akash/Documents/my_python_code/ran/CSCN8010-lab-submissions/students_submissions/8947100/lab4.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m params_linear \u001b[39m=\u001b[39m num_features \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# Number of features plus one for the intercept\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akash/Documents/my_python_code/ran/CSCN8010-lab-submissions/students_submissions/8947100/lab4.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 2. Polynomial Regression on BMI\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/akash/Documents/my_python_code/ran/CSCN8010-lab-submissions/students_submissions/8947100/lab4.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m params_bmi_poly \u001b[39m=\u001b[39m poly_reg_bmi\u001b[39m.\u001b[39;49mfit_transform(X_train[:, \u001b[39m2\u001b[39;49m])\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/akash/Documents/my_python_code/ran/CSCN8010-lab-submissions/students_submissions/8947100/lab4.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# 3. Multivariate Polynomial Regression\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/akash/Documents/my_python_code/ran/CSCN8010-lab-submissions/students_submissions/8947100/lab4.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m params_all_poly \u001b[39m=\u001b[39m poly_reg_all\u001b[39m.\u001b[39mfit_transform(X_train)\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:322\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    305\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    Compute number of output features.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39m        Fitted transformer.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     _, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mshape\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree, Integral):\n\u001b[0;32m    325\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    939\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    943\u001b[0m         )\n\u001b[0;32m    945\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    946\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.03259528  0.08540807 -0.0105172   0.11019775 -0.00620595  0.00133873\n  0.114509   -0.04069594  0.01750591  0.05954058 -0.046085    0.04768465\n  0.00564998 -0.03099563  0.05415152 -0.00512814 -0.00943939  0.0250506\n  0.12852056  0.01427248 -0.00081689 -0.03099563  0.00457217  0.00996123\n -0.03099563 -0.03854032  0.00241654 -0.02560657 -0.06656343 -0.03961813\n -0.04716281 -0.03207344  0.00241654  0.04552903 -0.0547075  -0.03854032\n -0.01590626 -0.01159501 -0.08919748 -0.02560657  0.02289497  0.06169621\n -0.00728377  0.08001901  0.06061839  0.05630715 -0.02560657  0.00457217\n  0.00672779 -0.0277622  -0.04716281 -0.00405033 -0.03961813 -0.06548562\n  0.0703187   0.02720622  0.02397278 -0.08380842  0.07139652  0.04121778\n -0.02237314  0.07139652 -0.05901875  0.06924089  0.00672779  0.0164281\n  0.05415152 -0.04177375  0.04013997  0.06816308 -0.05901875 -0.04824063\n -0.02452876  0.07247433 -0.0816528   0.09295276  0.04445121  0.00457217\n -0.05578531 -0.046085   -0.02991782  0.0347509  -0.01375064  0.00996123\n  0.00564998 -0.04824063 -0.03422907 -0.02560657  0.08864151  0.00672779\n -0.02991782  0.06061839  0.01103904  0.04660684  0.08109682  0.03367309\n  0.00133873  0.00564998 -0.01482845  0.03906215  0.10480869  0.12744274\n  0.06492964 -0.02991782 -0.00728377  0.04768465 -0.00836158  0.05954058\n -0.03315126 -0.06225218 -0.02345095 -0.01267283 -0.07518593 -0.00943939\n -0.04177375  0.0164281   0.08864151  0.00241654  0.05522933 -0.04716281\n -0.03530688 -0.02345095  0.04013997 -0.0105172   0.02181716  0.02073935\n -0.01590626  0.00888341 -0.01375064  0.07678558 -0.04069594  0.00672779\n  0.03690653 -0.02452876 -0.0191397  -0.0816528   0.00349435 -0.02452876\n  0.00026092  0.00133873  0.00457217 -0.06656343 -0.03315126 -0.00836158\n -0.00189471 -0.03854032  0.04984027 -0.02991782 -0.05362969  0.06169621\n  0.06816308 -0.08057499 -0.02452876 -0.05255187  0.07139652 -0.02345095\n  0.04229559  0.0433734  -0.02884001 -0.03099563 -0.02129532 -0.02021751\n  0.01211685 -0.07195249  0.03367309 -0.03854032 -0.05794093  0.0164281\n  0.07462995 -0.05686312  0.08540807 -0.00836158 -0.06764124 -0.03638469\n  0.02612841 -0.00512814  0.05630715 -0.03854032 -0.03638469  0.16085492\n -0.03099563  0.01750591 -0.046085    0.00996123 -0.07087468 -0.046085\n -0.00512814 -0.02237314  0.09403057  0.00457217 -0.0730303   0.12528712\n -0.00081689 -0.05794093  0.01858372  0.05954058 -0.02884001  0.07139652\n -0.00836158 -0.01698407  0.03043966 -0.00297252  0.11127556 -0.00728377\n  0.05630715 -0.06225218  0.06169621 -0.00836158 -0.02560657  0.07355214\n -0.02560657 -0.0105172  -0.00836158  0.12313149  0.04984027  0.03582872\n -0.02452876  0.06061839 -0.01267283  0.00672779  0.04552903  0.00349435\n  0.03906215  0.097264    0.09834182 -0.03099563  0.05415152  0.0347509\n  0.06061839 -0.03207344 -0.05578531  0.06385183 -0.02345095  0.03151747\n -0.01267283  0.00133873 -0.03638469 -0.03207344 -0.01590626 -0.05147406\n -0.03422907  0.01427248  0.01211685  0.04660684 -0.06332999 -0.07734155\n  0.13714305  0.0519959  -0.00728377 -0.00943939 -0.00297252  0.02828403\n -0.00836158 -0.00189471 -0.02021751 -0.04069594  0.01535029 -0.02021751\n -0.06009656  0.06708527  0.00133873  0.0433734  -0.00189471  0.01103904\n  0.00457217 -0.046085    0.0250506  -0.02452876 -0.00728377  0.00996123\n -0.06656343 -0.01590626 -0.0547075  -0.02668438 -0.06440781 -0.04177375\n -0.01159501 -0.01482845  0.05954058 -0.02237314  0.05307371 -0.06225218\n  0.02612841 -0.04177375 -0.0191397   0.09295276 -0.00081689  0.01858372\n -0.05578531 -0.046085   -0.00512814  0.09618619 -0.00405033  0.00564998\n -0.06440781 -0.02345095 -0.00620595  0.03043966 -0.03315126  0.01750591\n -0.0730303  -0.05686312 -0.00297252  0.03367309 -0.07626374  0.03043966\n -0.02021751 -0.02345095  0.02828403].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Number of parameters for each model\n",
    "\n",
    "# 1. Multivariate Linear Regression\n",
    "num_features = X_train.shape[1]\n",
    "params_linear = num_features + 1  # Number of features plus one for the intercept\n",
    "\n",
    "# 2. Polynomial Regression on BMI\n",
    "params_bmi_poly = poly_reg_bmi.fit_transform(X_train[:, 2]).shape[1]\n",
    "\n",
    "# 3. Multivariate Polynomial Regression\n",
    "params_all_poly = poly_reg_all.fit_transform(X_train).shape[1]\n",
    "\n",
    "# Explanation\n",
    "print(\"Number of Parameters for Each Model:\")\n",
    "print(f\"Multivariate Linear Regression: {params_linear} parameters\")\n",
    "print(f\"Polynomial Regression on BMI: {params_bmi_poly} parameters\")\n",
    "print(f\"Multivariate Polynomial Regression: {params_all_poly} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
